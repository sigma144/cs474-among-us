{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from gym import spaces\n",
    "from IPython import display\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "\n",
    "UP = 0; DOWN = 1; LEFT = 2; RIGHT = 3; WAIT = 4; NOT_FOUND = 5;\n",
    "DIRECTIONS = [(0, -1), (0, 1), (-1, 0), (1, 0), (0, 0)]\n",
    "\n",
    "class Space:\n",
    "    def __init__(self, space_map):\n",
    "        self.space_map = OrderedDict(space_map)\n",
    "        self.space = spaces.MultiDiscrete([j for i in self.space_map.values() for j in i])\n",
    "        self.space_discrete = spaces.Discrete([j for i in self.space_map.values() for j in i][0])\n",
    "    def get_space(self):\n",
    "        return self.space\n",
    "    def get_space_discrete(self):\n",
    "        return self.space_discrete\n",
    "    def make_array(self, obs):\n",
    "        return [j for i in OrderedDict(obs).values() for j in i]\n",
    "    def make_dict(self, lst):\n",
    "        d = OrderedDict()\n",
    "        index = 0\n",
    "        for k,v in self.space_map.items():\n",
    "            d[k] = lst[index:index+len(v)]\n",
    "            index += len(v)\n",
    "        return d\n",
    "    \n",
    "class MemorySpace:\n",
    "    def __init__(self, space_map):\n",
    "        for k,v in list(space_map.items()):\n",
    "            space_map[k + '~PREV'] = v\n",
    "        self.space_map = OrderedDict(space_map)\n",
    "        self.space = spaces.MultiDiscrete([j for i in self.space_map.values() for j in i])\n",
    "        self.space_discrete = spaces.Discrete([j for i in self.space_map.values() for j in i][0])\n",
    "    def get_space(self):\n",
    "        return self.space\n",
    "    def get_space_discrete(self):\n",
    "        return self.space_discrete\n",
    "    def make_array(self, obs, prev_obs):\n",
    "        return [j for i in obs.values() for j in i] + [j for i in prev_obs.values() for j in i]\n",
    "    def make_dict(self, lst):\n",
    "        d = OrderedDict()\n",
    "        index = 0\n",
    "        for k,v in self.space_map.items():\n",
    "            d[k] = lst[index:index+len(v)]\n",
    "            index += len(v)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PLAYERS = 5\n",
    "NUM_IMPOSTOR = 1\n",
    "NUM_TASKS = 4\n",
    "KILL_COOLDOWN = 3\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, world, start_pos=(0,0), impostor=False):\n",
    "        self.world = world\n",
    "        self.map = world.map\n",
    "        self.x, self.y = start_pos\n",
    "        self.world[self.x][self.y].append(self)\n",
    "        \n",
    "        self.last_dir = 0\n",
    "        self.alive = True\n",
    "        self.impostor = impostor\n",
    "        self.kill_cooldown = KILL_COOLDOWN // 2\n",
    "        \n",
    "        self.tasks = world.spawn_tasks(4)\n",
    "        \n",
    "    def repr(self):\n",
    "        return 'P'\n",
    "        \n",
    "    def move(self, direction):\n",
    "        if not self.can_move(direction):\n",
    "            return\n",
    "        self.map[self.x][self.y].remove(self)\n",
    "        change = DIRECTIONS[direction]\n",
    "        self.x += change[0]\n",
    "        self.y += change[1]\n",
    "        self.map[self.x][self.y].append(self)\n",
    "        self.last_dir = direction\n",
    "        if self.world.meetings and not self.impostor and self.alive and \\\n",
    "            any(len(self.world.body_map[pos[0]][pos[1]]) > 0 for pos in self.get_all_adjacent_pos()):\n",
    "            self.world.meeting = True\n",
    "        \n",
    "    def can_move(self, direction):\n",
    "        if direction == UP and self.y > 0:\n",
    "            return 1\n",
    "        if direction == DOWN and self.y < self.world.dims[1] - 1:\n",
    "            return 1\n",
    "        if direction == LEFT and self.x > 0:\n",
    "            return 1\n",
    "        if direction == RIGHT and self.x < self.world.dims[0] - 1:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def move_random(self):\n",
    "        self.move(random.randrange(4))\n",
    "        \n",
    "    def get_adjacent_pos(self, direction):\n",
    "        return self.x + DIRECTIONS[direction][0], self.y + DIRECTIONS[direction][1]\n",
    "    \n",
    "    def get_all_adjacent_pos(self):\n",
    "        pos = [(self.x + DIRECTIONS[d][0], self.y + DIRECTIONS[d][1]) for d in range(5) if self.can_move(d)]\n",
    "        return pos\n",
    "    \n",
    "    def is_task_in_dir(self, direction):\n",
    "        pos = self.get_adjacent_pos(direction)\n",
    "        if not self.can_move(direction):\n",
    "            return 0\n",
    "        return self.tasks[pos[0]][pos[1]] > 0\n",
    "    \n",
    "    def is_player_in_dir(self, direction):\n",
    "        pos = self.get_adjacent_pos(direction)\n",
    "        if not self.can_move(direction):\n",
    "            return 0\n",
    "        if len(self.world[pos[0]][pos[1]]) == 1 and self.world[pos[0]][pos[1]][0] == self:\n",
    "            return 0\n",
    "        return len(self.world[pos[0]][pos[1]]) > 0\n",
    "\n",
    "    def is_body_in_dir(self, direction):\n",
    "        pos = self.get_adjacent_pos(direction)\n",
    "        if not self.can_move(direction):\n",
    "            return 0\n",
    "        return len(self.world.body_map[pos[0]][pos[1]]) > 0\n",
    "    \n",
    "    def loc_player(self, player_num):\n",
    "        player = self.world.players[player_num]\n",
    "        for d in range(5):\n",
    "            if not self.can_move(d):\n",
    "                continue\n",
    "            pos = self.get_adjacent_pos(d)\n",
    "            if player in self.world[pos[0]][pos[1]]:\n",
    "                return d\n",
    "        return NOT_FOUND\n",
    "        \n",
    "    def do_task(self):\n",
    "        if self.impostor or self.tasks[self.x][self.y] == 0:\n",
    "            return 0\n",
    "        self.tasks[self.x][self.y] -= 1\n",
    "        self.world.required_tasks -= 1\n",
    "        return 1\n",
    "    \n",
    "    def kill(self):\n",
    "        if self.kill_cooldown > 0 or len(self.world[self.x][self.y]) <= 1:\n",
    "            return 0\n",
    "        if self.world[self.x][self.y][0].impostor:\n",
    "            kill_player = self.world[self.x][self.y][1]\n",
    "        else:\n",
    "            kill_player = self.world[self.x][self.y][0]\n",
    "        kill_player.alive = False\n",
    "        kill_player.map[kill_player.x][kill_player.y].remove(kill_player)\n",
    "        kill_player.map = self.world.dead_map\n",
    "        kill_player.map[kill_player.x][kill_player.y].append(kill_player)\n",
    "        self.world.body_map[kill_player.x][kill_player.y].append(kill_player)\n",
    "        self.world.alive_crew -= 1\n",
    "        self.kill_cooldown = KILL_COOLDOWN\n",
    "        for d in range(5):\n",
    "            if self.is_player_in_dir(d):\n",
    "                self.world.caught = self\n",
    "        return 1\n",
    "    \n",
    "    def take_random_action(self):\n",
    "        if self.impostor:\n",
    "            if len(self.world[self.x][self.y]) == 2 and all([self.is_player_in_dir(d) == 0 for d in range(4)]) \\\n",
    "            and self.world.players[0] not in self.world[self.x][self.y]:\n",
    "                self.kill()\n",
    "            self.move(random.randrange(4))\n",
    "        else:\n",
    "            if self.is_task_in_dir(WAIT):\n",
    "                self.do_task()\n",
    "            else:\n",
    "                self.move(random.randrange(4))\n",
    "    \n",
    "    def get_visible_players(self):\n",
    "        return self.world.map[self.x][self.y][:]\n",
    "\n",
    "class World:\n",
    "    def __init__(self, dims, meetings=True):\n",
    "        self.map = [[[] for i in range(dims[1])] for i in range(dims[0])]\n",
    "        self.dead_map = [[[] for i in range(dims[1])] for i in range(dims[0])]\n",
    "        self.body_map = [[[] for i in range(dims[1])] for i in range(dims[0])]\n",
    "        self.dims = dims\n",
    "        self.required_tasks = 0\n",
    "        self.meeting = False\n",
    "        self.meetings = meetings\n",
    "        self.voted = None\n",
    "        self.caught = None\n",
    "        self.alive_crew = NUM_PLAYERS - NUM_IMPOSTOR\n",
    "        self.alive_impostor = NUM_IMPOSTOR\n",
    "        self.required_tasks = NUM_TASKS * self.alive_crew\n",
    "        self.players = [Player(self) for i in range(NUM_PLAYERS)]\n",
    "        if NUM_IMPOSTOR > 0:\n",
    "            self.players[random.randrange(1, NUM_PLAYERS)].impostor = True\n",
    "    def spawn_tasks(self, x):\n",
    "        task_map = [[0 for i in range(self.dims[1])] for i in range(self.dims[0])]\n",
    "        for i in range(x):\n",
    "            task_map[random.randrange(self.dims[0])][random.randrange(self.dims[1])] += 1\n",
    "        return task_map\n",
    "    def __getitem__(self, key):\n",
    "        return self.map[key]\n",
    "    def perform_meeting(self, votes):\n",
    "        self.votes = [v if i >= len(self.players) or self.players[i].alive else 0 for i, v in enumerate(votes)]\n",
    "        highest = max(self.votes)\n",
    "        voted = [i for i, v in enumerate(self.votes) if v == highest]\n",
    "        if len(voted) > 1:\n",
    "            self.voted = -1\n",
    "        else:\n",
    "            self.voted = voted[0]\n",
    "            if voted[0] < NUM_PLAYERS:\n",
    "                self.players[self.voted].alive = False\n",
    "                if self.players[self.voted].impostor:\n",
    "                    self.alive_impostor -= 1\n",
    "                else:\n",
    "                    self.alive_crew -= 1\n",
    "        for x in range(self.dims[0]):\n",
    "            for y in range(self.dims[1]):\n",
    "                self.map[x][y].clear()\n",
    "                self.dead_map[x][y].clear()\n",
    "                self.body_map[x][y].clear()\n",
    "        for p in self.players:\n",
    "            p.map[0][0].append(p)\n",
    "            p.x = p.y = 0\n",
    "            p.kill_cooldown = KILL_COOLDOWN\n",
    "        self.meeting = False\n",
    "    def check_win(self):\n",
    "        if self.alive_crew <= self.alive_impostor:\n",
    "            return -1\n",
    "        if self.required_tasks <= 0 or self.caught or (self.alive_impostor == 0 and NUM_IMPOSTOR > 0):\n",
    "            return 1\n",
    "        return 0\n",
    "    def render(self):\n",
    "        if self.voted != None:\n",
    "            print(self.votes)\n",
    "            if self.voted == -1:\n",
    "                print(\"No one was ejected. (Tie)\")\n",
    "            elif self.voted >= NUM_PLAYERS:\n",
    "                print(\"No one was ejected. (Skipped)\")\n",
    "            elif self.players[self.voted].impostor:\n",
    "                print(\"Player \" + str(self.voted) + \" was the Impostor.\")\n",
    "            else:\n",
    "                print(\"Player \" + str(self.voted) + \" was not the Impostor.\")\n",
    "            self.voted = None\n",
    "        else:\n",
    "            #for x in range(self.dims[0]):\n",
    "            #    for y in range(self.dims[1]):\n",
    "            #        if len(self.map[x][y]) == 0 and len(self.body_map[x][y]) > 0:\n",
    "            #            print('X', end='')\n",
    "            #        else:\n",
    "            #            print(len(self.map[x][y]), end='')\n",
    "            #    print()\n",
    "            if self.meeting and self.check_win() == 0:\n",
    "                print(\"Body Reported!\")\n",
    "        if self.alive_impostor == 0 and NUM_IMPOSTOR > 0:\n",
    "            print(\"Crewmates Win!\")\n",
    "        if self.alive_crew <= NUM_IMPOSTOR:\n",
    "            print(\"Impostors Win!\")\n",
    "        elif self.caught:\n",
    "            print(\"Caught! Crewmates Win!\")\n",
    "        elif self.required_tasks <= 0:\n",
    "            print(\"All tasks complete! Crewmates Win!\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEnvironmentC2(gym.Env): #Finding killer\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        super(TestEnvironmentC2, self).__init__()\n",
    "        self.obs_space = MemorySpace({'dir_came_from':[4],\n",
    "                            'can_move':[2 for i in range(4)],\n",
    "                            'player_loc':[5 for i in range(NUM_PLAYERS)],\n",
    "                            'is_alive':[2 for i in range(NUM_PLAYERS)],\n",
    "                            #'is_body_in_dir':[2 for i in range(5)],\n",
    "                               })\n",
    "        self.observation_space = self.obs_space.get_space()\n",
    "        self.act_space = Space({'move':[5],\n",
    "                                'vote':[NUM_PLAYERS + 1]\n",
    "                               })\n",
    "        self.action_space = self.act_space.get_space()\n",
    "        self.last_obs = None\n",
    "    def reset(self):\n",
    "        self.world = World((4, 3))\n",
    "        self.players = self.world.players\n",
    "        self.total_steps = 0\n",
    "        return self._next_observation()\n",
    "    def _next_observation(self, dup=True):\n",
    "        obs = {'dir_came_from':[self.players[0].last_dir],\n",
    "              'can_move':[self.players[0].can_move(d) for d in range(4)],\n",
    "               'player_loc':[self.players[0].loc_player(i) for i in range(NUM_PLAYERS)],\n",
    "               'is_alive':[int(self.players[i].alive) for i in range(NUM_PLAYERS)],\n",
    "               #'is_body_in_dir':[self.players[0].is_body_in_dir(d) for d in range(5)],\n",
    "              }\n",
    "        last = self.last_obs if self.last_obs != None else obs\n",
    "        self.last_obs = obs\n",
    "        return self.obs_space.make_array(obs, last)\n",
    "    def step(self, action):\n",
    "        self.total_steps += 1\n",
    "        obs = self._next_observation()\n",
    "        reward = self._take_action(action)\n",
    "        game_result = 10 * self.world.check_win()\n",
    "        if game_result == 0 and self.total_steps >= 100:\n",
    "            game_result = 0.1\n",
    "        reward += game_result\n",
    "        done = (game_result != 0)\n",
    "        for p in self.players:\n",
    "            p.kill_cooldown -= 1\n",
    "        return obs, reward, done, {}\n",
    "    def _take_action(self, action):\n",
    "        action = self.act_space.make_dict(action)\n",
    "        reward = 0\n",
    "        if self.world.meeting:\n",
    "            votes = [0 for p in range(len(self.players)+1)]\n",
    "            #action['vote'][0] = random.randrange(len(votes))\n",
    "            votes[action['vote'][0]] = 1\n",
    "            self.world.perform_meeting(votes)\n",
    "            if action['vote'][0] < NUM_PLAYERS and not self.players[action['vote'][0]].impostor:\n",
    "                return -1\n",
    "            return 0\n",
    "        else:\n",
    "            #action['move'][0] = random.randrange(5)\n",
    "            self.players[0].move(action['move'][0])\n",
    "            for p in self.players[1:]:\n",
    "                p.take_random_action()\n",
    "            return 0\n",
    "    def render(self, mode='human', close=False):\n",
    "        self.world.render()\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353.8353621959686\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2, DQN, deepq\n",
    "import time\n",
    "\n",
    "env = TestEnvironmentC2()\n",
    "#env = DummyVecEnv([lambda: TestEnvironmentC()])\n",
    "model = PPO2(MlpPolicy, env, policy_kwargs=dict(net_arch=[64, 64]))\n",
    "#model = PPO2(MlpLstmPolicy, env, nminibatches=1)\n",
    "#model = DQN(deepq.LnMlpPolicy, env)\n",
    "start = time.time()\n",
    "model.learn(total_timesteps=500000)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg:  -4.180499999999985\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "NUM_TRIALS = 3000\n",
    "for i in range(NUM_TRIALS):\n",
    "    obs = env.reset()\n",
    "    for i in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        #env.render()\n",
    "        total += rewards\n",
    "        if dones:\n",
    "            break\n",
    "    #print(\"Total steps: \", env.total_steps)\n",
    "    #total += env.total_steps\n",
    "env.close()\n",
    "print(\"Avg: \", total / NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crewmate Do Tasks\n",
    "\n",
    "Random agent: -7.68, -8.71, -8.87\n",
    "PPO (64, 64) Learner: 9.87, 10.1, 7.93\n",
    "PPO (32, 64, 32) Learner: 7.21, 7.12, -1.56\n",
    "PPO (32, 32, 32, 32, 32) Learner: 5.18, 5.52, 4.243\n",
    "PPO (64, 64, 32) Learner: 4.45, 5.29, 6.61\n",
    "PPO (64, 64, 64) Learner: 10.33, 10.06, 10.37\n",
    "PPO (128, 128) Learner: 10.73, 11.00, 10.57\n",
    "DQN (64, 64) Learner: -17.64, -17.81\n",
    "DQN With Normalization: -18.87, -17.47\n",
    "\n",
    "PPO (64, 64) Learner 5x: 11.33, 11.31\n",
    "PPO (64, 64, 64) Learner 5x: 11.43, 11.36\n",
    "PPO (128, 128) Learner 5x: 11.24, 11.24\n",
    "\n",
    "Impostor Kill Players\n",
    "\n",
    "Random agent: -5.82, -5.60, -5.06\n",
    "PPO (64, 64) Learner: 3.21, 4.66, 4.15\n",
    "PPO (64, 64) Learner 5x: 4.12, 4.28\n",
    "PPO (64, 64, 64) Learner: 4.48, 4.25, 4.04\n",
    "PPO (64, 64, 64) Learner 5x: 3.78, 4.43\n",
    "PPO (128, 128) Learner: 3.98, 4.07, 3.41\n",
    "\n",
    "Crewmate Vote Out Impostor\n",
    "\n",
    "Random agent: -6.21, -6.13, -6.19\n",
    "PPO (64, 64) Learner: -6.26, -6.56, -6.35\n",
    "PPO (64, 64) Learner 5x: -4.89, -4.29\n",
    "PPO (64, 64) Learner 5x with memory: -4.32, -4.62, -4.18\n",
    "PPO (64, 64, 64) Learner: -5.03, -4.59, -5.79\n",
    "PPO (64, 64, 64) Learner 5x: -4.68, -4.89\n",
    "PPO (128, 128) Learner: -5.75, -6.59, -4.47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PLAYERS = 1\n",
    "NUM_IMPOSTOR = 0\n",
    "\n",
    "class TestEnvironmentC(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        super(TestEnvironmentC, self).__init__()\n",
    "        self.obs_space = Space({'dir_came_from':[4],\n",
    "                            'can_move':[2 for i in range(4)],\n",
    "                            'is_task':[2 for i in range(5)],\n",
    "                               })\n",
    "        self.observation_space = self.obs_space.get_space()\n",
    "        self.act_space = Space({'move':[5]\n",
    "                               })\n",
    "        self.action_space = self.act_space.get_space_discrete()\n",
    "    def reset(self):\n",
    "        self.world = World((3, 3))\n",
    "        self.players = self.world.players\n",
    "        self.total_steps = 0\n",
    "        return self.next_observation()\n",
    "    def next_observation(self):\n",
    "        obs = {'dir_came_from':[self.players[0].last_dir],\n",
    "              'can_move':[self.players[0].can_move(d) for d in range(4)],\n",
    "               'is_task':[self.players[0].is_task_in_dir(d) for d in range(5)]\n",
    "              }\n",
    "        return self.obs_space.make_array(obs)\n",
    "    def step(self, action):\n",
    "        self.total_steps += 1\n",
    "        obs = self.next_observation()\n",
    "        reward = self.take_action_discrete(action)\n",
    "        game_result = 10 * self.world.check_win()\n",
    "        if game_result == 0 and self.total_steps >= 100:\n",
    "            game_result = -10\n",
    "        reward += game_result\n",
    "        done = (game_result != 0)\n",
    "        return obs, reward - 0.1, done, {}\n",
    "    def take_action(self, action):\n",
    "        action = self.act_space.make_dict(action)\n",
    "        reward = 0\n",
    "        #action['move'][0] = random.randrange(5)\n",
    "        if action['move'][0] == WAIT:\n",
    "            reward += self.players[0].do_task()\n",
    "        else:\n",
    "            self.players[0].move(action['move'][0])\n",
    "        return reward\n",
    "    def take_action_discrete(self, action):\n",
    "        reward = 0\n",
    "        #action = random.randrange(5)\n",
    "        if action == WAIT:\n",
    "            reward += self.players[0].do_task()\n",
    "        else:\n",
    "            self.players[0].move(action)\n",
    "        return reward\n",
    "    def render(self, mode='human', close=False):\n",
    "        self.world.render()\n",
    "        print('Tasks left: ' + str(self.world.required_tasks))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEnvironmentI(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        super(TestEnvironmentI, self).__init__()\n",
    "        self.obs_space = Space({'dir_came_from':[4],\n",
    "                            'can_move':[2 for i in range(4)],\n",
    "                            'is_player':[2 for i in range(5)],\n",
    "                               })\n",
    "        self.observation_space = self.obs_space.get_space()\n",
    "        self.act_space = Space({'move':[4],\n",
    "                                'kill':[2]\n",
    "                               })\n",
    "        self.action_space = self.act_space.get_space()\n",
    "    def reset(self):\n",
    "        self.world = World((4, 3), meetings=False)\n",
    "        self.players = self.world.players\n",
    "        self.total_steps = 0\n",
    "        return self._next_observation()\n",
    "    def _next_observation(self):\n",
    "        obs = {'dir_came_from':[self.players[0].last_dir],\n",
    "              'can_move':[self.players[0].can_move(d) for d in range(4)],\n",
    "               'is_player':[self.players[0].is_player_in_dir(d) for d in range(5)]\n",
    "              } #dead?\n",
    "        return self.obs_space.make_array(obs)\n",
    "    def step(self, action):\n",
    "        self.total_steps += 1\n",
    "        obs = self._next_observation()\n",
    "        reward = self._take_action(action)\n",
    "        game_result = -10 * self.world.check_win()\n",
    "        if game_result == 0 and self.total_steps >= 100:\n",
    "            game_result = -10\n",
    "        reward += game_result\n",
    "        done = (game_result != 0)\n",
    "        for p in self.players:\n",
    "            p.kill_cooldown -= 1\n",
    "        return obs, reward - 0.1, done, {}\n",
    "    def _take_action(self, action):\n",
    "        action = self.act_space.make_dict(action)\n",
    "        reward = 0\n",
    "        #if random.randrange(2):\n",
    "        if action['kill'][0]:\n",
    "            reward += self.players[0].kill()\n",
    "        #self.players[0].move(random.randrange(4))\n",
    "        self.players[0].move(action['move'][0])\n",
    "        for p in self.players[1:]:\n",
    "            p.take_random_action()\n",
    "        return reward\n",
    "    def render(self, mode='human', close=False):\n",
    "        self.world.render()\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
